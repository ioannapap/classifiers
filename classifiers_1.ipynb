{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "import scipy as sp\n",
    "import string\n",
    "import json\n",
    "import re\n",
    "import sklearn.metrics as metrics\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "import matplotlib.pyplot as  plt\n",
    "import seaborn as sns\n",
    "import sklearn\n",
    "from sklearn.metrics import confusion_matrix\n",
    "####\n",
    "from sklearn.model_selection import train_test_split, cross_val_predict\n",
    "from sklearn import linear_model\n",
    "import statsmodels.api as sm\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import sklearn.linear_model as linear_model\n",
    "import sklearn.model_selection as model_selection\n",
    "\n",
    "from sklearn import svm\n",
    "from sklearn import tree\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import BernoulliNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# open training dataset and parse recipes\n",
    "\n",
    "with open('train.json') as cooking_file:  \n",
    "    \n",
    "    data = json.load(cooking_file)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#COUNTVECTORIZER\n",
    "#removing punctuations and spaces before fixing the data and keep them all in a dict  (italian, mexican)\n",
    "\n",
    "punctuations = '''!()-[]{};:'\"\\,<>./?@#$%^&*_~'''\n",
    "\n",
    "def gather_recipes(recipes, cuisine_country):\n",
    "    \n",
    "    data_list = []\n",
    "    \n",
    "    for _object in recipes:\n",
    "        \n",
    "        if _object.get('cuisine') == cuisine_country:\n",
    "            \n",
    "            ingredients = _object.get('ingredients') \n",
    "\n",
    "            _id = _object.get('id')\n",
    "            \n",
    "            for i in ingredients:\n",
    "                \n",
    "                _dict = dict()\n",
    "                ingr = i.replace(' ', '').lower()\n",
    "                    \n",
    "                for ch in ingr: \n",
    "                    \n",
    "                    if ch in punctuations: \n",
    "                        \n",
    "                        ingr = ingr.replace(ch, '')  \n",
    "                \n",
    "                _dict['ingredients'] = ingr                \n",
    "                _dict['id'] = _id\n",
    "                data_list.append(_dict)\n",
    "                \n",
    "    return data_list\n",
    "\n",
    "\n",
    "clean_italian_cuisine_data = gather_recipes(data, 'italian')\n",
    "clean_mexican_cuisine_data = gather_recipes(data, 'mexican')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating dfs  (italian, mexican)\n",
    "\n",
    "italian_df = DataFrame(clean_italian_cuisine_data)\n",
    "italian_ingredients = list(set(italian_df.ingredients))\n",
    "\n",
    "mexican_df = DataFrame(clean_mexican_cuisine_data)\n",
    "mexican_ingredients = list(set(mexican_df.ingredients))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fixing data for CountVectorizer (italian_df)\n",
    "\n",
    "it_unique_ids = []\n",
    "it_ingredients = []\n",
    "it_grouped = italian_df.groupby('id')\n",
    "\n",
    "for ids, ing in it_grouped:\n",
    "    \n",
    "    it_unique_ids.append(ids)\n",
    "    \n",
    "    row = str(ing)\n",
    "    row = row.replace('ingredients','')\n",
    "    row = row.replace('id', '')\n",
    "    row = row.replace('\\n', '')\n",
    "    row = re.sub('[0-9]+', '', row)\n",
    "    row = row.split( )\n",
    "    row = ' '.join(row)\n",
    "    \n",
    "    it_ingredients.append(row)\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fixing data for CountVectorizer (mexican_df)\n",
    "\n",
    "mex_unique_ids = []\n",
    "mex_ingredients = []\n",
    "mex_grouped = mexican_df.groupby('id')\n",
    "\n",
    "for ids, ing in mex_grouped:\n",
    "    \n",
    "    mex_unique_ids.append(ids)\n",
    "    \n",
    "    row = str(ing)\n",
    "    row = row.replace('ingredients','')\n",
    "    row = row.replace('id', '')\n",
    "    row = row.replace('\\n', '')\n",
    "    row = re.sub('[0-9]+', '', row)\n",
    "    row = row.split( )\n",
    "    row = ' '.join(row)\n",
    "    \n",
    "    mex_ingredients.append(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#using CountVectorizer  (italian, mexican) and adding one column Cuisine\n",
    "\n",
    "it_vectorizer = CountVectorizer(analyzer = 'word', binary = True)\n",
    "it_array = it_vectorizer.fit_transform(it_ingredients)\n",
    "it_array = it_array.toarray()\n",
    "it_df = DataFrame(it_array, columns = it_vectorizer.get_feature_names(), index = it_unique_ids)\n",
    "it_df['Cuisine'] = 0 #italian\n",
    "it_df.to_csv('it_cleandata.csv', index_label = 'ID')\n",
    "#print(it_df)\n",
    "\n",
    "mex_vectorizer = CountVectorizer(analyzer = 'word', binary = True)\n",
    "mex_array = mex_vectorizer.fit_transform(mex_ingredients)\n",
    "mex_array = mex_array.toarray()\n",
    "mex_df = DataFrame(mex_array, columns = mex_vectorizer.get_feature_names(), index = mex_unique_ids)\n",
    "mex_df['Cuisine'] = 1 #mexican\n",
    "mex_df.to_csv('mex_cleandata.csv', index_label = 'ID')\n",
    "#print(mex_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#putting mexican and italian in one DataFrame\n",
    "\n",
    "df = pd.DataFrame(it_df)\n",
    "df = df.append(mex_df, sort = False)\n",
    "df.fillna(0, inplace = True)\n",
    "df = df.astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TFIDFVECTORIZER\n",
    "#removing punctuations before fixing the data and keep them all in a dict  (italian, mexican)\n",
    "\n",
    "def gather_recipes(recipes, cuisine_country):\n",
    "    \n",
    "    data_list = []\n",
    "    \n",
    "    for _object in recipes:\n",
    "        \n",
    "        if _object.get('cuisine') == cuisine_country:\n",
    "            \n",
    "            ingredients = _object.get('ingredients') \n",
    "            \n",
    "            _id = _object.get('id')\n",
    "            \n",
    "            for i in ingredients:\n",
    "                \n",
    "                _dict = dict()\n",
    "                ingr = i.lower()\n",
    "                    \n",
    "                for ch in ingr: \n",
    "                    \n",
    "                    if ch in punctuations: \n",
    "                        \n",
    "                        ingr = ingr.replace(ch, '')  \n",
    "                \n",
    "                _dict['ingredients'] = ingr                \n",
    "                _dict['id'] = _id\n",
    "                data_list.append(_dict)\n",
    "                \n",
    "    return data_list\n",
    "\n",
    "clean2_italian_cuisine_data = gather_recipes(data, 'italian')\n",
    "clean2_mexican_cuisine_data = gather_recipes(data, 'mexican')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating dfs2  (italian, mexican)\n",
    "\n",
    "italian2_df = DataFrame(clean2_italian_cuisine_data)\n",
    "mexican2_df = DataFrame(clean2_mexican_cuisine_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fixing data for TfidfVectorizer (italian, mexican)\n",
    "\n",
    "it2_unique_ids = []\n",
    "it2_ingredients = []\n",
    "it2_grouped = italian2_df.groupby('id')\n",
    "\n",
    "for ids, ing in it2_grouped:\n",
    "    \n",
    "    it2_unique_ids.append(ids)\n",
    "    \n",
    "    row = str(ing)\n",
    "    row = row.replace('ingredients','')\n",
    "    row = row.replace('id', '')\n",
    "    row = row.replace('\\n', '')\n",
    "    row = re.sub('[0-9]+', '', row)\n",
    "    row = row.split( )\n",
    "    row = ' '.join(row)\n",
    "    it2_ingredients.append(row)\n",
    "\n",
    "    \n",
    "mex2_unique_ids = []\n",
    "mex2_ingredients = []\n",
    "mex2_grouped = mexican2_df.groupby('id')\n",
    "\n",
    "for ids, ing in mex2_grouped:\n",
    "    \n",
    "    mex2_unique_ids.append(ids)\n",
    "    \n",
    "    row = str(ing)\n",
    "    row = row.replace('ingredients','')\n",
    "    row = row.replace('id', '')\n",
    "    row = row.replace('\\n', '')\n",
    "    row = re.sub('[0-9]+', '', row)\n",
    "    row = row.split( )\n",
    "    row = ' '.join(row)\n",
    "    mex2_ingredients.append(row)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#using TfidfVectorizer  (italian, mexican) and adding one column Cuisine\n",
    "\n",
    "it2_vectorizer = TfidfVectorizer(analyzer = 'word', binary = True)\n",
    "it2_array = it2_vectorizer.fit_transform(it2_ingredients)\n",
    "it2_array = it2_array.toarray()\n",
    "it2_df = DataFrame(it2_array, columns = it2_vectorizer.get_feature_names(), index = it2_unique_ids)\n",
    "it2_df['Cuisine'] = 0 #italian\n",
    "it2_df.to_csv('it2_cleandata.csv', index_label = 'ID')\n",
    "#print(it2_df)\n",
    "\n",
    "mex2_vectorizer = CountVectorizer(analyzer = 'word', binary = True)\n",
    "mex2_array = mex2_vectorizer.fit_transform(mex2_ingredients)\n",
    "mex2_array = mex2_array.toarray()\n",
    "mex2_df = DataFrame(mex2_array, columns = mex2_vectorizer.get_feature_names(), index = mex2_unique_ids)\n",
    "mex2_df['Cuisine'] = 1 #mexican\n",
    "mex2_df.to_csv('mex2_cleandata.csv', index_label = 'ID')\n",
    "#print(mex2_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       abbamele   ac  accent  acini  acorn  active  added  adobo  agave  aged  \\\n",
      "4           0.0  0.0     0.0    0.0    0.0     0.0    0.0    0.0    0.0   0.0   \n",
      "14          0.0  0.0     0.0    0.0    0.0     0.0    0.0    0.0    0.0   0.0   \n",
      "20          0.0  0.0     0.0    0.0    0.0     0.0    0.0    0.0    0.0   0.0   \n",
      "56          0.0  0.0     0.0    0.0    0.0     0.0    0.0    0.0    0.0   0.0   \n",
      "62          0.0  0.0     0.0    0.0    0.0     0.0    0.0    0.0    0.0   0.0   \n",
      "...         ...  ...     ...    ...    ...     ...    ...    ...    ...   ...   \n",
      "49678       0.0  0.0     0.0    0.0    0.0     0.0    0.0    0.0    0.0   0.0   \n",
      "49687       0.0  0.0     0.0    0.0    0.0     0.0    0.0    0.0    0.0   0.0   \n",
      "49707       0.0  0.0     0.0    0.0    0.0     0.0    0.0    0.0    0.0   0.0   \n",
      "49709       0.0  0.0     0.0    0.0    0.0     0.0    0.0    0.0    0.0   0.0   \n",
      "49717       0.0  0.0     0.0    0.0    0.0     0.0    0.0    1.0    0.0   0.0   \n",
      "\n",
      "       ...  wensleydale  wesson  wheel  wing  wish  wolf  xanthan  yellowtail  \\\n",
      "4      ...          0.0     0.0    0.0   0.0   0.0   0.0      0.0         0.0   \n",
      "14     ...          0.0     0.0    0.0   0.0   0.0   0.0      0.0         0.0   \n",
      "20     ...          0.0     0.0    0.0   0.0   0.0   0.0      0.0         0.0   \n",
      "56     ...          0.0     0.0    0.0   0.0   0.0   0.0      0.0         0.0   \n",
      "62     ...          0.0     0.0    0.0   0.0   0.0   0.0      0.0         0.0   \n",
      "...    ...          ...     ...    ...   ...   ...   ...      ...         ...   \n",
      "49678  ...          0.0     0.0    0.0   0.0   0.0   0.0      0.0         0.0   \n",
      "49687  ...          0.0     0.0    0.0   0.0   0.0   0.0      0.0         0.0   \n",
      "49707  ...          0.0     0.0    0.0   0.0   0.0   0.0      0.0         0.0   \n",
      "49709  ...          0.0     0.0    0.0   0.0   0.0   0.0      0.0         0.0   \n",
      "49717  ...          0.0     0.0    0.0   0.0   0.0   0.0      0.0         0.0   \n",
      "\n",
      "       yuca  zero  \n",
      "4       0.0   0.0  \n",
      "14      0.0   0.0  \n",
      "20      0.0   0.0  \n",
      "56      0.0   0.0  \n",
      "62      0.0   0.0  \n",
      "...     ...   ...  \n",
      "49678   0.0   0.0  \n",
      "49687   0.0   0.0  \n",
      "49707   0.0   0.0  \n",
      "49709   0.0   0.0  \n",
      "49717   0.0   0.0  \n",
      "\n",
      "[14276 rows x 2007 columns]\n"
     ]
    }
   ],
   "source": [
    "#putting mexican and italian in one DataFrame\n",
    "\n",
    "df2 = pd.DataFrame(it2_df)\n",
    "df2 = df2.append(mex2_df, sort = False)\n",
    "df2.fillna(0, inplace = True)\n",
    "print(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multiple Logistic Regression \n",
    "lr_m = linear_model.LogisticRegression()\n",
    "\n",
    "# Support Vector Machines\n",
    "svm_m = svm.SVC()\n",
    "\n",
    "#Decision Trees\n",
    "dtree = tree.DecisionTreeClassifier()\n",
    "\n",
    "#k-NN\n",
    "knn = KNeighborsClassifier(n_neighbors = 3)\n",
    "\n",
    "# Naive Bayes\n",
    "gnb = BernoulliNB(binarize = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********* CountVectorizer *********\n",
      "(14276, 3976)\n"
     ]
    }
   ],
   "source": [
    "print('********* CountVectorizer *********')\n",
    "X = df.loc[:, df.columns != 'Cuisine'].values  #all columns with values except Cuisine column\n",
    "print(X.shape)\n",
    "\n",
    "Y = df['Cuisine'] #just the ids in a list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jo/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/jo/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/jo/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/jo/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/jo/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****Logistic Regression mean scores****\n",
      "scores: {'fit_time': array([2.31020904, 2.0499053 , 1.96741199, 1.95003009, 2.04533005]), 'score_time': array([0.13899088, 0.13435984, 0.10122919, 0.1008358 , 0.127141  ]), 'test_accuracy': array([0.96813725, 0.97233894, 0.96778711, 0.96671338, 0.9688157 ]), 'test_precision_weighted': array([0.96837424, 0.97241883, 0.96788602, 0.96682014, 0.96883557]), 'test_recall_weighted': array([0.96813725, 0.97233894, 0.96778711, 0.96671338, 0.9688157 ]), 'test_f1_weighted': array([0.96809087, 0.97231503, 0.96775533, 0.96667911, 0.96879857])}\n",
      "\n",
      "mean score test accuracy: 0.9687584774624636\n",
      "\n",
      "mean score test precision weighted: 0.9688669615432207\n",
      "\n",
      "mean score test recall weighted: 0.9687584774624636\n",
      "\n",
      "mean score test f1-measure weighted: 0.968727783410316\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jo/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/jo/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/jo/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/jo/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/jo/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix: [[7679  159]\n",
      " [ 287 6151]]\n"
     ]
    }
   ],
   "source": [
    "s = ['accuracy', 'precision_weighted', 'recall_weighted', 'f1_weighted']\n",
    "scores_ = model_selection.cross_validate(lr_m, X, Y, scoring = s, cv = 5)                                 \n",
    "print('****Logistic Regression mean scores****')\n",
    "print('scores:', scores_)\n",
    "print('\\nmean score test accuracy:', scores_['test_accuracy'].mean())\n",
    "print('\\nmean score test precision weighted:', scores_['test_precision_weighted'].mean())\n",
    "print('\\nmean score test recall weighted:', scores_['test_recall_weighted'].mean())\n",
    "print('\\nmean score test f1-measure weighted:', scores_['test_f1_weighted'].mean())\n",
    "\n",
    "Y_pred = cross_val_predict(lr_m, X, Y, cv = 5)\n",
    "conf_matrix = confusion_matrix(Y, Y_pred)\n",
    "print('Confusion Matrix:', conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_ = model_selection.cross_validate(svm_m, X, Y, scoring = s, cv = 5)                                 \n",
    "print('****SVM mean scores****')\n",
    "print('scores:', scores_)\n",
    "print('\\nmean score test accuracy:', scores_['test_accuracy'].mean())\n",
    "print('\\nmean score test precision weighted:', scores_['test_precision_weighted'].mean())\n",
    "print('\\nmean score test recall weighted:', scores_['test_recall_weighted'].mean())\n",
    "print('\\nmean score test f1-measure weighted:', scores_['test_f1_weighted'].mean())\n",
    "\n",
    "Y_pred = cross_val_predict(svm_m, X, Y, cv = 5)\n",
    "conf_matrix = confusion_matrix(Y, Y_pred)\n",
    "print('Confusion Matrix:', conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****d-tree mean scores****\n",
      "scores: {'fit_time': array([29.54377818, 24.38601685, 28.68981385, 28.7813518 , 20.56070304]), 'score_time': array([0.10330701, 0.09680319, 0.08734488, 0.08625317, 0.08562613]), 'test_accuracy': array([0.93767507, 0.95133053, 0.93872549, 0.94253679, 0.93062369]), 'test_precision_weighted': array([0.93766729, 0.95138607, 0.93875214, 0.9425827 , 0.93080495]), 'test_recall_weighted': array([0.93767507, 0.95133053, 0.93872549, 0.94253679, 0.93062369]), 'test_f1_weighted': array([0.93767072, 0.95128451, 0.93873592, 0.94255228, 0.93066835])}\n",
      "\n",
      "mean score test accuracy: 0.9401783137922303\n",
      "\n",
      "mean score test precision weighted: 0.9402386303037866\n",
      "\n",
      "mean score test recall weighted: 0.9401783137922303\n",
      "\n",
      "mean score test f1-measure weighted: 0.9401823547873281\n",
      "Confusion Matrix: [[7412  426]\n",
      " [ 436 6002]]\n"
     ]
    }
   ],
   "source": [
    "scores_ = model_selection.cross_validate(dtree, X, Y, scoring = s, cv = 5)                                 \n",
    "print('****d-tree mean scores****')\n",
    "print('scores:', scores_)\n",
    "print('\\nmean score test accuracy:', scores_['test_accuracy'].mean())\n",
    "print('\\nmean score test precision weighted:', scores_['test_precision_weighted'].mean())\n",
    "print('\\nmean score test recall weighted:', scores_['test_recall_weighted'].mean())\n",
    "print('\\nmean score test f1-measure weighted:', scores_['test_f1_weighted'].mean())\n",
    "\n",
    "Y_pred = cross_val_predict(dtree, X, Y, cv = 5)\n",
    "conf_matrix = confusion_matrix(Y, Y_pred)\n",
    "print('Confusion Matrix:', conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_ = model_selection.cross_validate(knn, X, Y, scoring = s, cv = 5)                                 \n",
    "print('****k-NN mean scores****')\n",
    "print('scores:', scores_)\n",
    "print('\\nmean score test accuracy:', scores_['test_accuracy'].mean())\n",
    "print('\\nmean score test precision weighted:', scores_['test_precision_weighted'].mean())\n",
    "print('\\nmean score test recall weighted:', scores_['test_recall_weighted'].mean())\n",
    "print('\\nmean score test f1-measure weighted:', scores_['test_f1_weighted'].mean())\n",
    "\n",
    "Y_pred = cross_val_predict(knn, X, Y, cv = 5)\n",
    "conf_matrix = confusion_matrix(Y, Y_pred)\n",
    "print('Confusion Matrix:', conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_ = model_selection.cross_validate(gnb, X, Y, scoring = s, cv = 5)                                 \n",
    "print('****Naive-Bayes mean scores****')\n",
    "print('scores:', scores_)\n",
    "print('\\nmean score test accuracy:', scores_['test_accuracy'].mean())\n",
    "print('\\nmean score test precision weighted:', scores_['test_precision_weighted'].mean())\n",
    "print('\\nmean score test recall weighted:', scores_['test_recall_weighted'].mean())\n",
    "print('\\nmean score test f1-measure weighted:', scores_['test_f1_weighted'].mean())\n",
    "\n",
    "Y_pred = cross_val_predict(gnb, X, Y, cv = 5)\n",
    "conf_matrix = confusion_matrix(Y, Y_pred)\n",
    "print('Confusion Matrix:', conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********* TfidfVectorizer *********\n",
      "(14276, 2006)\n"
     ]
    }
   ],
   "source": [
    "print('********* TfidfVectorizer *********')\n",
    "X = df2.loc[:, df2.columns != 'Cuisine'].values  #all columns with values except Cuisine column\n",
    "print(X.shape)\n",
    "\n",
    "Y = df2['Cuisine'] #just the ids in a list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jo/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/jo/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/jo/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/jo/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/jo/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****Logistic Regression mean scores****\n",
      "scores: {'fit_time': array([0.8786943 , 0.82599497, 0.81366682, 0.82805109, 0.800915  ]), 'score_time': array([0.02411008, 0.02425408, 0.02461004, 0.02333093, 0.02349782]), 'test_accuracy': array([0.99194678, 0.9929972 , 0.9929972 , 0.99544499, 0.99404345]), 'test_precision_weighted': array([0.9920632 , 0.9930854 , 0.9930854 , 0.99548247, 0.99410738]), 'test_recall_weighted': array([0.99194678, 0.9929972 , 0.9929972 , 0.99544499, 0.99404345]), 'test_f1_weighted': array([0.99193982, 0.99299199, 0.99299199, 0.99544284, 0.99403972])}\n",
      "\n",
      "mean score test accuracy: 0.9934859227503194\n",
      "\n",
      "mean score test precision weighted: 0.9935647664446428\n",
      "\n",
      "mean score test recall weighted: 0.9934859227503194\n",
      "\n",
      "mean score test f1-measure weighted: 0.9934812704260404\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jo/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/jo/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/jo/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/jo/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix: [[7838    0]\n",
      " [  93 6345]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jo/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "s = ['accuracy', 'precision_weighted', 'recall_weighted', 'f1_weighted']\n",
    "scores_ = model_selection.cross_validate(lr_m, X, Y, scoring = s, cv = 5)                                 \n",
    "print('****Logistic Regression mean scores****')\n",
    "print('scores:', scores_)\n",
    "print('\\nmean score test accuracy:', scores_['test_accuracy'].mean())\n",
    "print('\\nmean score test precision weighted:', scores_['test_precision_weighted'].mean())\n",
    "print('\\nmean score test recall weighted:', scores_['test_recall_weighted'].mean())\n",
    "print('\\nmean score test f1-measure weighted:', scores_['test_f1_weighted'].mean())\n",
    "\n",
    "Y_pred = cross_val_predict(lr_m, X, Y, cv = 5)\n",
    "conf_matrix = confusion_matrix(Y, Y_pred)\n",
    "print('Confusion Matrix:', conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_ = model_selection.cross_validate(svm_m, X, Y, scoring = s, cv = 5)                                 \n",
    "print('****SVM mean scores****')\n",
    "print('scores:', scores_)\n",
    "print('\\nmean score test accuracy:', scores_['test_accuracy'].mean())\n",
    "print('\\nmean score test precision weighted:', scores_['test_precision_weighted'].mean())\n",
    "print('\\nmean score test recall weighted:', scores_['test_recall_weighted'].mean())\n",
    "print('\\nmean score test f1-measure weighted:', scores_['test_f1_weighted'].mean())\n",
    "\n",
    "Y_pred = cross_val_predict(svm_m, X, Y, cv = 5)\n",
    "conf_matrix = confusion_matrix(Y, Y_pred)\n",
    "print('Confusion Matrix:', conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****d-tree mean scores****\n",
      "scores: {'fit_time': array([4.13364887, 4.21988606, 3.97078705, 3.98422503, 4.41084409]), 'score_time': array([0.051373  , 0.04051805, 0.04074407, 0.04045296, 0.0480361 ]), 'test_accuracy': array([0.99754902, 0.99754902, 0.9982493 , 0.99824807, 0.99894884]), 'test_precision_weighted': array([0.99755991, 0.99755433, 0.99825486, 0.99825365, 0.99895085]), 'test_recall_weighted': array([0.99754902, 0.99754902, 0.9982493 , 0.99824807, 0.99894884]), 'test_f1_weighted': array([0.99754841, 0.99754859, 0.99824899, 0.99824776, 0.99894873])}\n",
      "\n",
      "mean score test accuracy: 0.9981088511087688\n",
      "\n",
      "mean score test precision weighted: 0.9981147215558022\n",
      "\n",
      "mean score test recall weighted: 0.9981088511087688\n",
      "\n",
      "mean score test f1-measure weighted: 0.9981084968101144\n",
      "Confusion Matrix: [[7837    1]\n",
      " [  24 6414]]\n"
     ]
    }
   ],
   "source": [
    "scores_ = model_selection.cross_validate(dtree, X, Y, scoring = s, cv = 5)                                 \n",
    "print('****d-tree mean scores****')\n",
    "print('scores:', scores_)\n",
    "print('\\nmean score test accuracy:', scores_['test_accuracy'].mean())\n",
    "print('\\nmean score test precision weighted:', scores_['test_precision_weighted'].mean())\n",
    "print('\\nmean score test recall weighted:', scores_['test_recall_weighted'].mean())\n",
    "print('\\nmean score test f1-measure weighted:', scores_['test_f1_weighted'].mean())\n",
    "\n",
    "Y_pred = cross_val_predict(dtree, X, Y, cv = 5)\n",
    "conf_matrix = confusion_matrix(Y, Y_pred)\n",
    "print('Confusion Matrix:', conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_ = model_selection.cross_validate(knn, X, Y, scoring = s, cv = 5)                                 \n",
    "print('****k-NN mean scores****')\n",
    "print('scores:', scores_)\n",
    "print('\\nmean score test accuracy:', scores_['test_accuracy'].mean())\n",
    "print('\\nmean score test precision weighted:', scores_['test_precision_weighted'].mean())\n",
    "print('\\nmean score test recall weighted:', scores_['test_recall_weighted'].mean())\n",
    "print('\\nmean score test f1-measure weighted:', scores_['test_f1_weighted'].mean())\n",
    "\n",
    "Y_pred = cross_val_predict(knn, X, Y, cv = 5)\n",
    "conf_matrix = confusion_matrix(Y, Y_pred)\n",
    "print('Confusion Matrix:', conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_ = model_selection.cross_validate(gnb, X, Y, scoring = s, cv = 5)                                 \n",
    "print('****Naive-Bayes mean scores****')\n",
    "print('scores:', scores_)\n",
    "print('\\nmean score test accuracy:', scores_['test_accuracy'].mean())\n",
    "print('\\nmean score test precision weighted:', scores_['test_precision_weighted'].mean())\n",
    "print('\\nmean score test recall weighted:', scores_['test_recall_weighted'].mean())\n",
    "print('\\nmean score test f1-measure weighted:', scores_['test_f1_weighted'].mean())\n",
    "\n",
    "Y_pred = cross_val_predict(gnb, X, Y, cv = 5)\n",
    "conf_matrix = confusion_matrix(Y, Y_pred)\n",
    "print('Confusion Matrix:', conf_matrix)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
